%% Example of a LaTeX source file for a COLING-2012 submission
%% last updated: July 10, 2012
%% Optional instructions for authors within the tex file are provided as comments and start with 'for authors:...'
\documentclass[10pt,a5paper,twoside]{article}
\usepackage{coling2012}
\title{United We Stand: Tweet Pooling for a better LDA}
%for authors: in case of more than four author names ref. to commented line below 
%\author{$Annie~SMITH^{1, 2}~~~LI~Xiao Dong^{1, 3}$\\$~~~Third~Author^{1, 2}~~~Fourth~Author^{1, 3}~~~ Fifth~Author^{2, 3}$\\
\author{$Author1^{1}~~~Author2^{2}$\\
{\small  	(1) INSTITUTE\_1, address 1\\ 
 		(2) INSTITUTE\_2, address 2\\
  \texttt{mail-id, mail-id} \\ 
}}

\begin{document}
\maketitle
%% The first mandatory ABSTRACT (\abstractEn) section below is for the English language
\abstractEn{  %ABSTRACT}{
DEMO - Social networks such as Facebook, LinkedIn, and Twitter have been
a crucial source of information for a wide spectrum of users. In
Twitter, popular information that is deemed important by the community propagates through the network. Studying the characteristics of content in the messages becomes important for a number of tasks, such as breaking news detection, personalized message recommendation, friends recommendation, sentiment analysis and others. While many researchers wish to use standard text mining
tools to understand messages on Twitter, the restricted length of
those messages prevents them from being employed to their full
potential.
 \\\\}

%for authors: the line below is for instruction purposes and can be commented




%%-------------
%for authors: if only English language option is chosen comment the \abstractOL section above and use \keywordsEn below 
%for authors: else use add title and abstract to \abstractOL section above and use \keywordsOL below (case-sensitive commands)

%for authors: for keywords section either use \keywordsEn OR \keywordsOL below as relevant
%Example for English only keywords list
%\keywordsEn{Here a list of keywords in English}

%Example for English + optional language keywords list
\keywordsOL{Topic Modelling, LDA, Tweets}
{\\}
%%--------------

%\newpage
%================================================================
% section 1


% section 2
\section{Introduction}
% subsection 2.1
Some points to be covered here:
\begin{compactitem}
\item Twitter introduction and problems faced while analysing tweets
\item Motivation for Topic Modelling for tweets: information needs
\item Difficulties faced by general LDA on tweets
\item How we address these issues and our contribution\\
\end{compactitem}


%\subsection{General information}

\section{Topic Models : Latent Dirichlet Allocation}
A brief description of LDA.\\\\

\section{Pooling Schemes}
In this section we describe various tweet pooling schemes in detail.
\begin{compactenum}
\item Burst Score wise
\begin{compactitem}
\item Definition of Burst Score
\item Pooling by Burst Score
\end{compactitem}
\item Author-wise Pooling
\item Temporal Pooling
\begin{compactitem}
\item 30 minutes
\item Hourly
\end{compactitem}
\item Conversational
\item Hashtag-wise\\\\
\end{compactenum}

\section{Lexical Normalization of Hashtags}
In this section we describe hashtag normalization in the following 3 subsections.
\subsection{Scoping Hashtag Normalization}
\begin{compactitem}
\item Task definition
\item Figures / analysis of the types of hashtags we encounter in a dataset.\\
%\item \#NYTimes with \#NewYorkTimes
%\item \#fight4glory with \#fightforglory \\\\
\end{compactitem}

\subsection{Candidate Set Generation}
\begin{compactitem}
\item Letters
\item Numbers
\item Letters+Numbers
\item Abbreviations
\item Common prefix/suffix - substring
\end{compactitem}

\subsection{Context Based Pruning}
For each of the hashtags obtained from the above method we compare the tweet collection of each hashtag with the hashtag in question (using the number of common words as a basic metric ) and based on some filtering score we select the top candidate.\\\\



\section{Experimental Setup}
\subsection{Dataset Description}
Here we describe the datasets we create in detail:
\begin{compactitem}
\item Generic
\item Specific
\item WDS Conference
\item other\\
\end{compactitem}

\subsection{Document Characteristics after Pooling}
A big table which describes document characteristics for each pooling scheme in each dataset.\\

\subsection{Evaluation Metrics}
We test the different pooling schemes on a variety of metrics for different goals.
\begin{compactenum}
\item Purity
\begin{compactitem}
\item to see which schemes is best suited to reproduce known clusters
\end{compactitem}
\item NMI
\item PMI
\begin{compactitem}
\item to measure which scheme gives the most coherent topics
\item We modify this metric so that instead of external source it uses the tweet dataset itself to calculate the probabilities.\\\\
\end{compactitem}
\end{compactenum}

\section{Results}
\begin{compactenum}
\item Purity
\begin{compactitem}
\item a single bar graph with Pooling scheme on X-Axis and Purity Score on Y-axis for all the 3 datasets
\end{compactitem}
\item NMI
\begin{compactitem}
\item a scatter graph with \#topics on x-axis and NMI score on y-axis
\end{compactitem}
\item{PMI}
\begin{compactitem}
\item a single bar graph with Pooling scheme on X-Axis and PMI Score on Y-axis for all the 3 datasets
\end{compactitem}
\end{compactenum}

\section{Observations}
Herewe list down pointwise our observations, the affect of various settings and our main findings/insights.\\\\

\section{Related Work}
Here we discuss in detail the prior work done on Topic Modelling for tweets, majorly dividing it into 4 categories:
\begin{compactenum}
\item Topic Models for tweets
\item Visualizing Topic Models
\item Evaluating Topic Models
\item Application of Topic Models for twitter tasks(events, earthquake, et cetera)\\
\end{compactenum}

\section{Conclusion}
\section*{Acknowledgments}

%'apalike-fr' style below applies smallcaps style on author names
%in order to apply 'apalike-fr' the babel package must be given [frenchb] option instead of [english]
% \usepackage[frenchb]{babel} also causes title "References" to render with French accents like "R\'ef\'erences"
%\bibliographystyle{apalike-fr}

%'apa' style does not apply "smallcaps style" on author names and goes with the [english] option in the babel package

\bibliographystyle{apa}

\bibliography{colingbiblio}
\nocite{TALN2007,LaigneletRioult09,LanglaisPatry07,au1972,cks1981,mb2012}

%%================================================================
\end{document}
